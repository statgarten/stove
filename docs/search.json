[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2023 stove authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (â€œSoftwareâ€), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED â€œâ€, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Yeonchan Seong. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Seong Y (2023). stove: Stove. R package version 1.1, https://github.com/statgarten/stove.","code":"@Manual{,   title = {stove: Stove},   author = {Yeonchan Seong},   year = {2023},   note = {R package version 1.1},   url = {https://github.com/statgarten/stove}, }"},{"path":"/index.html","id":"yellow_heart-stove-","dir":"","previous_headings":"","what":"Stove","title":"Stove","text":"stove package provides functions ML modeling. Packages Tidymodels used, configured easy ML beginners use. Although belongs statgarten whose packages incorporated shiny app, stove package also can used console.","code":""},{"path":"/index.html","id":"wrench-install","dir":"","previous_headings":"","what":"ğŸ”§ Install","title":"Stove","text":"","code":"# install.packages(\"devtools\") devtools::install_github(\"statgarten/stove\")"},{"path":[]},{"path":"/index.html","id":"id_1-sample-data-import","dir":"","previous_headings":"Example Code","what":"1. Sample Data Import","title":"Stove","text":"","code":"# remotes::install_github(\"statgarten/datatoys\") library(stove) library(datatoys) library(dplyr)  set.seed(1234)  cleaned_data <- datatoys::bloodTest  cleaned_data <- cleaned_data %>%   mutate_at(vars(SEX, ANE, IHD, STK), factor) %>%   mutate(TG = ifelse(TG < 150, 0, 1)) %>%   mutate_at(vars(TG), factor) %>%   group_by(TG) %>%   sample_n(500) # TG(0):TG(1) = 500:500"},{"path":"/index.html","id":"id_2-data-split-and-define-preprocessing","dir":"","previous_headings":"Example Code","what":"2. Data split and Define preprocessing","title":"Stove","text":"","code":"target_var <- \"TG\" train_set_ratio <- 0.7 seed <- 1234 formula <- paste0(target_var, \" ~ .\")  # Split data  split_tmp <- stove::trainTestSplit(data = cleaned_data,                                    target = target_var,                                    prop = train_set_ratio,                                    seed = seed                                    )  data_train <- split_tmp[[1]] # train data data_test <- split_tmp[[2]] # test data data_split <- split_tmp[[3]] # whole data with split information  # Define preprocessing recipe for cross validation  rec <- stove::prepForCV(data = data_train,                         formula = formula,                         imputation = T,                         normalization = T,                         seed = seed                         )"},{"path":"/index.html","id":"id_3-modeling","dir":"","previous_headings":"Example Code","what":"3. Modeling","title":"Stove","text":"can compare several modelsâ€™ performance visualize . documents contain example codes modeling workflow using stove.","code":"# User input  mode <- \"classification\" algo <- \"logisticRegression\" # Custom name engine <- \"glmnet\" # glmnet (default) v <- 2 metric <- \"roc_auc\" # roc_auc (default), accuracy gridNum <- 5 iter <- 10 seed <- 1234  # Modeling using logistic regression algorithm  finalized <- stove::logisticRegression(   algo = algo,   engine = engine,   mode = mode,   trainingData = data_train,   splitedData = data_split,   formula = formula,   rec = rec,   v = v,   gridNum = gridNum,   iter = iter,   metric = metric,   seed = seed )"},{"path":"/index.html","id":"white_check_mark-recommendation","dir":"","previous_headings":"","what":"âœ… Recommendation","title":"Stove","text":"training ML model, amount data required depends complexity task want solve complexity learning algorithm. â€˜stoveâ€™ support training process without cross-validation. recommend training model data least 1,000 rows.","code":""},{"path":"/index.html","id":"blush-authors","dir":"","previous_headings":"","what":"ğŸ˜Š Authors","title":"Stove","text":"Yeonchan Seong @ycseong07","code":""},{"path":"/index.html","id":"memo-license","dir":"","previous_headings":"","what":"ğŸ“ License","title":"Stove","text":"Copyright Â©ï¸ 2022 Yeonchan Seong project MIT licensed","code":""},{"path":"/index.html","id":"clipboard-dependency","dir":"","previous_headings":"","what":"ğŸ“‹ Dependency","title":"Stove","text":"assertthat - 0.2.1 base64enc - 0.1-3 bayesplot - 1.10.0 boot - 1.3-28.1 C50 - 0.1.7 callr - 3.7.3 class - 7.3-20 cli - 3.6.0 cluster - 2.1.4 codetools - 0.2-18 colorspace - 2.0-3 colourpicker - 1.2.0 combinat - 0.0-8 cowplot - 1.1.1 crayon - 1.5.2 crosstalk - 1.2.0 Cubist - 0.4.1 data.table - 1.14.6 DBI - 1.1.3 dials - 1.1.0 DiceDesign - 1.9 digest - 0.6.31 discrim - 1.0.0 dplyr - 1.0.10 DT - 0.26 dygraphs - 1.1.1.6 ellipsis - 0.3.2 factoextra - 1.0.7 fansi - 1.0.3 fastmap - 1.1.0 forcats - 0.5.2 foreach - 1.5.2 Formula - 1.2-4 furrr - 0.3.1 future - 1.30.0 future.apply - 1.10.0 generics - 0.1.3 ggplot2 - 3.4.0 ggrepel - 0.9.2 glmnet - 4.1-6 globals - 0.16.2 glue - 1.6.2 gower - 1.0.1 GPfit - 1.0-8 gridExtra - 2.3 gtable - 0.3.1 gtools - 3.9.4 hardhat - 1.2.0 haven - 2.5.1 highr - 0.1 hms - 1.1.2 htmltools - 0.5.4 htmlwidgets - 1.6.1 httpuv - 1.6.7 igraph - 1.3.5 inline - 0.3.19 inum - 1.0-4 ipred - 0.9-13 iterators - 1.0.14 kknn - 1.3.1 klaR - 1.7-1 labelled - 2.10.0 later - 1.3.0 lattice - 0.20-45 lava - 1.7.1 lhs - 1.1.6 libcoin - 1.0-9 lifecycle - 1.0.3 listenv - 0.9.0 lme4 - 1.1-31 loo - 2.5.1 lubridate - 1.9.0 magrittr - 2.0.3 markdown - 1.4 MASS - 7.3-58.1 Matrix - 1.5-3 matrixStats - 0.63.0 mime - 0.12 miniUI - 0.1.1.1 minqa - 1.2.5 munsell - 0.5.0 mvtnorm - 1.1-3 naivebayes - 0.9.7 nlme - 3.1-161 nloptr - 2.0.3 nnet - 7.3-18 parallelly - 1.33.0 parsnip - 1.0.3 partykit - 1.2-16 pillar - 1.8.1 pkgbuild - 1.4.0 pkgconfig - 2.0.3 plyr - 1.8.8 prettyunits - 1.1.1 processx - 3.8.0 prodlim - 2019.11.13 promises - 1.2.0.1 ps - 1.7.0 purrr - 0.3.4 questionr - 0.7.7 R6 - 2.5.1 randomForest - 4.7-1.1 ranger - 0.14.1 RColorBrewer - 1.1-3 Rcpp - 1.0.9 RcppParallel - 5.1.6 recipes - 1.0.3 reshape2 - 1.4.4 rlang - rpart - 4.1.19 rsample - 1.1.1 rstan - 2.21.7 rstanarm - 2.21.3 rstantools - 2.2.0 rstudioapi - 0.14 scales - 1.2.1 sessioninfo - 1.2.2 shape - 1.4.6 shiny - 1.7.4 shinyjs - 2.1.0 shinystan - 2.6.0 shinythemes - 1.2.0 StanHeaders - 2.21.0-7 stringi - 1.7.8 stringr - 1.5.0 survival - 3.5-0 threejs - 0.3.3 tibble - 3.1.8 tidyr - 1.2.1 tidyselect - 1.2.0 timechange - 0.1.1 timeDate - 4022.108 treesnip - 0.1.0.9001 tune - 1.0.1 utf8 - 1.2.2 vctrs - 0.5.1 withr - 2.5.0 workflows - 1.1.2 xtable - 1.8-4 xts - 0.12.2 yardstick - 1.1.0 zoo - 1.8-11","code":""},{"path":"/reference/KNN.html","id":null,"dir":"Reference","previous_headings":"","what":"K-Nearest Neighbors â€” KNN","title":"K-Nearest Neighbors â€” KNN","text":"K-Nearest Neighbors","code":""},{"path":"/reference/KNN.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K-Nearest Neighbors â€” KNN","text":"","code":"KNN(   algo = \"KNN\",   engine = \"kknn\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/KNN.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K-Nearest Neighbors â€” KNN","text":"algo name algorithm can customized user (default: \"KNN\"). engine name software used fit model (\"kknn\" (default)). mode model type. \"classification\" \"regression\" (\"classification\" (default), \"regression\"). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/KNN.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"K-Nearest Neighbors â€” KNN","text":"function training user-defined K-Nearest Neighbors model. Hyperparameters tuning: neighbors","code":""},{"path":"/reference/MLP.html","id":null,"dir":"Reference","previous_headings":"","what":"neural network â€” MLP","title":"neural network â€” MLP","text":"neural network","code":""},{"path":"/reference/MLP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"neural network â€” MLP","text":"","code":"MLP(   algo = \"MLP\",   engine = \"nnet\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/MLP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"neural network â€” MLP","text":"algo name algorithm can customized user (default: \"MLP\"). engine name software used fit model (\"nnet\" (default)). mode model type. \"classification\" \"regression\" (\"classification\" (default), \"regression\"). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/MLP.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"neural network â€” MLP","text":"function training user-defined MLP model. Hyperparameters tuning: hidden_units, penalty, epochs","code":""},{"path":"/reference/SVMLinear.html","id":null,"dir":"Reference","previous_headings":"","what":"SVMLinear â€” SVMLinear","title":"SVMLinear â€” SVMLinear","text":"SVMLinear","code":""},{"path":"/reference/SVMLinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SVMLinear â€” SVMLinear","text":"","code":"SVMLinear(   algo = \"SVMLinear\",   engine = \"kernlab\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 15,   metric = NULL,   seed = 1234 )"},{"path":"/reference/SVMLinear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SVMLinear â€” SVMLinear","text":"algo name algorithm can customized user (default: \"SVMLinear\"). engine name software used fit model (\"kernlab\" (default)). mode model type. \"classification\" \"regression\" (\"classification\" (default), \"regression\"). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/SVMLinear.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SVMLinear â€” SVMLinear","text":"function training user-defined SVM Linear model.","code":""},{"path":"/reference/SVMPoly.html","id":null,"dir":"Reference","previous_headings":"","what":"SVMPoly â€” SVMPoly","title":"SVMPoly â€” SVMPoly","text":"SVMPoly","code":""},{"path":"/reference/SVMPoly.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SVMPoly â€” SVMPoly","text":"","code":"SVMPoly(   algo = \"SVMPoly\",   engine = \"kernlab\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 15,   metric = NULL,   seed = 1234 )"},{"path":"/reference/SVMPoly.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SVMPoly â€” SVMPoly","text":"algo name algorithm can customized user (default: \"SVMPoly\"). engine name software used fit model (\"kernlab\" (default)). mode model type. \"classification\" \"regression\" (\"classification\" (default), \"regression\"). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/SVMPoly.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SVMPoly â€” SVMPoly","text":"function training user-defined SVM Poly model.","code":""},{"path":"/reference/SVMRbf.html","id":null,"dir":"Reference","previous_headings":"","what":"SVMRbf â€” SVMRbf","title":"SVMRbf â€” SVMRbf","text":"SVMRbf","code":""},{"path":"/reference/SVMRbf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SVMRbf â€” SVMRbf","text":"","code":"SVMRbf(   algo = \"SVMRbf\",   engine = \"kernlab\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 15,   metric = NULL,   seed = 1234 )"},{"path":"/reference/SVMRbf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SVMRbf â€” SVMRbf","text":"algo name algorithm can customized user (default: \"SVMRbf\"). engine name software used fit model (\"kernlab\" (default)). mode model type. \"classification\" \"regression\" (\"classification\" (default), \"regression\"). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/SVMRbf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"SVMRbf â€” SVMRbf","text":"function training user-defined SVM Rbf model.","code":""},{"path":"/reference/bayesOptCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Bayesian optimization with cross validation â€” bayesOptCV","title":"Bayesian optimization with cross validation â€” bayesOptCV","text":"Bayesian optimization cross validation","code":""},{"path":"/reference/bayesOptCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bayesian optimization with cross validation â€” bayesOptCV","text":"","code":"bayesOptCV(   rec = NULL,   model = NULL,   v = NULL,   trainingData = NULL,   gridNum = NULL,   iter = NULL,   seed = NULL )"},{"path":"/reference/bayesOptCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bayesian optimization with cross validation â€” bayesOptCV","text":"rec recipe object including local preprocessing. model model object including list hyperparameters, engine mode. v Perform cross-validation dividing training data v folds. trainingData training data. gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. seed Seed reproducible results.","code":""},{"path":"/reference/bayesOptCV.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bayesian optimization with cross validation â€” bayesOptCV","text":"Optimize hyperparameters model Cross Validation Bayesian optimization.","code":""},{"path":"/reference/clusteringVis.html","id":null,"dir":"Reference","previous_headings":"","what":"clusteringVis â€” clusteringVis","title":"clusteringVis â€” clusteringVis","text":"clusteringVis","code":""},{"path":"/reference/clusteringVis.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"clusteringVis â€” clusteringVis","text":"","code":"clusteringVis(   data = NULL,   model = NULL,   maxK = \"15\",   nBoot = \"100\",   selectOptimal = \"silhouette\",   seedNum = \"6471\" )"},{"path":"/reference/clusteringVis.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"clusteringVis â€” clusteringVis","text":"data data model model maxK maxK nStart nStart","code":""},{"path":"/reference/clusteringVis.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"clusteringVis â€” clusteringVis","text":"Deprecated","code":""},{"path":"/reference/decisionTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Decision Tree â€” decisionTree","title":"Decision Tree â€” decisionTree","text":"Decision Tree","code":""},{"path":"/reference/decisionTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decision Tree â€” decisionTree","text":"","code":"decisionTree(   algo = \"Decision Tree\",   engine = \"rpart\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/decisionTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decision Tree â€” decisionTree","text":"algo name algorithm can customized user (default: \"Decision Tree\"). engine name software used fit model (\"rpart\" (default), \"C50\", \"partykit\"). mode model type. \"classification\" \"regression\" (\"classification\" (default), \"regression\"). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/decisionTree.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Decision Tree â€” decisionTree","text":"function training user-defined Decision Tree model. Hyperparameters tuning: tree_depth, min_n, cost_complexity","code":""},{"path":"/reference/evalMetricsR.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluation metrics for Regression â€” evalMetricsR","title":"Evaluation metrics for Regression â€” evalMetricsR","text":"Evaluation metrics Regression","code":""},{"path":"/reference/evalMetricsR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluation metrics for Regression â€” evalMetricsR","text":"","code":"evalMetricsR(modelsList, targetVar)"},{"path":"/reference/evalMetricsR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluation metrics for Regression â€” evalMetricsR","text":"modelsList ML ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ targetVar íƒ€ê²Ÿ ë³€ìˆ˜","code":""},{"path":"/reference/evalMetricsR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluation metrics for Regression â€” evalMetricsR","text":"ML ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° Regression ëª¨ë¸ë“¤ì— ëŒ€í•œ Evaluation metricsë¥¼ ìƒì„±í•©ë‹ˆë‹¤.","code":""},{"path":"/reference/fitBestModel.html","id":null,"dir":"Reference","previous_headings":"","what":"fitting in best model â€” fitBestModel","title":"fitting in best model â€” fitBestModel","text":"fitting best model","code":""},{"path":"/reference/fitBestModel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fitting in best model â€” fitBestModel","text":"","code":"fitBestModel(   optResult,   metric,   model,   formula,   trainingData,   splitedData,   modelName )"},{"path":"/reference/fitBestModel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fitting in best model â€” fitBestModel","text":"optResult result object bayesOptCV metric Baseline metric evaluating model performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\") model model object including list hyperparameters, engine mode. formula formula modeling trainingData training data. splitedData whole dataset including information fold modelName name model defined algorithm engine selected user","code":""},{"path":"/reference/fitBestModel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"fitting in best model â€” fitBestModel","text":"Get bayesOptCV function's return value fit model.","code":""},{"path":"/reference/gridSearchCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Grid search with cross validation â€” gridSearchCV","title":"Grid search with cross validation â€” gridSearchCV","text":"Grid search cross validation","code":""},{"path":"/reference/gridSearchCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grid search with cross validation â€” gridSearchCV","text":"","code":"gridSearchCV(   rec = NULL,   model = NULL,   v = NULL,   trainingData = NULL,   parameterGrid = NULL,   seed = NULL )"},{"path":"/reference/gridSearchCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grid search with cross validation â€” gridSearchCV","text":"rec ë°ì´í„°, ì „ì²˜ë¦¬ ì •ë³´ë¥¼ í¬í•¨í•œ recipe object model hyperparameters, ngine, mode ì •ë³´ê°€ í¬í•¨ëœ model object v v-fold cross validationì„ ì§„í–‰ (default: 5, ê° fold ë³„ë¡œ 30ê°œ ì´ìƒì˜ observationsê°€ ìˆì–´ì•¼ ìœ íš¨í•œ ëª¨ë¸ë§ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.) trainingData í›ˆë ¨ë°ì´í„° ì…‹ seed seedê°’ ì„¤ì • parameter_grid grid searchë¥¼ ìˆ˜í–‰í•  ë•Œ ê° hyperparameterì˜ ê°’ì„ ë‹´ì€ object","code":""},{"path":"/reference/gridSearchCV.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Grid search with cross validation â€” gridSearchCV","text":"í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ íƒìƒ‰í•˜ëŠ” Grid Searchì™€ ë°ì´í„° ì…‹ì„ ë‚˜ëˆ„ì–´ í‰ê°€í•˜ëŠ” cross validationì„ í•¨ê»˜ ìˆ˜í–‰í•©ë‹ˆë‹¤.","code":""},{"path":"/reference/kMeansClustering.html","id":null,"dir":"Reference","previous_headings":"","what":"K means clustering â€” kMeansClustering","title":"K means clustering â€” kMeansClustering","text":"K means clustering","code":""},{"path":"/reference/kMeansClustering.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"K means clustering â€” kMeansClustering","text":"","code":"kMeansClustering(   data,   maxK = 15,   nStart = 25,   iterMax = 10,   nBoot = 100,   algorithm = \"Hartigan-Wong\",   selectOptimal = \"silhouette\",   seedNum = 6471 )"},{"path":"/reference/kMeansClustering.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"K means clustering â€” kMeansClustering","text":"data ì „ì²˜ë¦¬ê°€ ì™„ë£Œëœ ë°ì´í„° maxK í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰ ì‹œ êµ°ì§‘ì„ 2, 3, ..., maxKê°œë¡œ ë¶„í•  (default: 15) iterMax ë°˜ë³µê³„ì‚°ì„ ìˆ˜í–‰í•  ìµœëŒ€ íšŸìˆ˜ (default: 10) nBoot gap staticticì„ ì‚¬ìš©í•´ í´ëŸ¬ìŠ¤í„°ë§ì„ ìˆ˜í–‰í•  ë•Œ Monte Carlo (bootstrap) ìƒ˜í”Œì˜ ê°œìˆ˜ (selectOptimal == \"gap_stat\" ì¼ ê²½ìš°ì—ë§Œ ì§€ì •, default: 100) algorithm K meansë¥¼ ìˆ˜í–‰í•  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ (\"Hartigan-Wong\" (default), \"Lloyd\", \"Forgy\", \"MacQueen\") selectOptimal ìµœì ì˜ Kê°’ì„ ì„ ì •í•  ë•Œ ì‚¬ìš©í•  method ì„ íƒ (\"silhouette\" (default), \"gap_stat\") seedNum seedê°’ ì„¤ì • nstart ëœë¤ ìƒ˜í”Œì— ëŒ€í•´ ì´ˆê¸° í´ëŸ¬ìŠ¤í„°ë§ì„ nstartë²ˆ ì‹œí–‰ (default: 25)","code":""},{"path":"/reference/kMeansClustering.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"K means clustering â€” kMeansClustering","text":"function K means clustering. parameters tuning: maxK, nstart","code":""},{"path":"/reference/lightGbm.html","id":null,"dir":"Reference","previous_headings":"","what":"Light GBM â€” lightGbm","title":"Light GBM â€” lightGbm","text":"Light GBM","code":""},{"path":"/reference/lightGbm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Light GBM â€” lightGbm","text":"","code":"lightGbm(   algo = \"lightGBM\",   engine = \"lightgbm\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 15,   metric = NULL,   seed = 1234 )"},{"path":"/reference/lightGbm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Light GBM â€” lightGbm","text":"algo name algorithm can customized user. (default: \"lightGBM\"). engine name software used fit model(\"lightgbm\" (default)). mode model type. \"classification\" \"regression\" (\"classification\" (default), \"regression\"). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/lightGbm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Light GBM â€” lightGbm","text":"function training user-defined Light GBM model. Hyperparameters tuning: tree_depth, trees, learn_rate, mtry, min_n, loss_reduction","code":""},{"path":"/reference/linearRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Linear Regression â€” linearRegression","title":"Linear Regression â€” linearRegression","text":"Linear Regression","code":""},{"path":"/reference/linearRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linear Regression â€” linearRegression","text":"","code":"linearRegression(   algo = \"Linear Regression\",   engine = \"glmnet\",   mode = \"regression\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = \"rmse\",   seed = 1234 )"},{"path":"/reference/linearRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linear Regression â€” linearRegression","text":"algo name algorithm can customized user (default: \"Linear Regression\"). engine name software used fit model (\"glmnet\" (default), \"lm\", \"glm\", \"stan\"). mode model type. \"classification\" \"regression\" (\"regression\" (default)). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/linearRegression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Linear Regression â€” linearRegression","text":"function training user-defined Linear Regression model. Hyperparameters tuning: penalty, mixture","code":""},{"path":"/reference/logisticRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Logistic Regression â€” logisticRegression","title":"Logistic Regression â€” logisticRegression","text":"function training user-defined Logistic regression model. function supports: binary classification","code":""},{"path":"/reference/logisticRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logistic Regression â€” logisticRegression","text":"","code":"logisticRegression(   algo = \"Logistic Regression\",   engine = \"glmnet\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = \"roc_auc\",   seed = 1234 )"},{"path":"/reference/logisticRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logistic Regression â€” logisticRegression","text":"algo name algorithm can customized user (default: \"Logistic Regression\"). engine name software used fit model (Option: \"glmnet\" (default)). mode model type. \"classification\" \"regression\" (Option: \"classification\" (default)). trainingData training data. splitedData whole dataset including information fold formula formula modeling rec Recipe object containing preprocessing information cross-validation v Applying v-fold cross validation modeling process (default: 5) gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/logisticRegression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Logistic Regression â€” logisticRegression","text":"Hyperparameters tuning: penalty, mixture","code":""},{"path":"/reference/multinomialRegression.html","id":null,"dir":"Reference","previous_headings":"","what":"Multinomial Regression â€” multinomialRegression","title":"Multinomial Regression â€” multinomialRegression","text":"function training user-defined Multinomial regression model. function supports: multinomial classification","code":""},{"path":"/reference/multinomialRegression.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multinomial Regression â€” multinomialRegression","text":"","code":"multinomialRegression(   algo = \"Multinomial Regression\",   engine = \"glmnet\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = \"roc_auc\",   seed = 1234 )"},{"path":"/reference/multinomialRegression.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multinomial Regression â€” multinomialRegression","text":"algo name algorithm can customized user (default: \"Multinomial Regression\"). engine name software used fit model (Option: \"glmnet\" (default)). mode model type. \"classification\" \"regression\" (Option: \"classification\" (default)). trainingData data frame training. splitedData data frame including metadata split. formula formula modeling. rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/multinomialRegression.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multinomial Regression â€” multinomialRegression","text":"Hyperparameters tuning: penalty, mixture","code":""},{"path":"/reference/naiveBayes.html","id":null,"dir":"Reference","previous_headings":"","what":"Naive Bayes â€” naiveBayes","title":"Naive Bayes â€” naiveBayes","text":"Naive Bayes","code":""},{"path":"/reference/naiveBayes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Naive Bayes â€” naiveBayes","text":"","code":"naiveBayes(   algo = \"Naive Bayes\",   engine = \"klaR\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/naiveBayes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Naive Bayes â€” naiveBayes","text":"algo name algorithm can customized user (default: \"Naive Bayes\"). engine name software used fit model (\"klaR\" (default), naivebayes). mode model type. \"classification\" \"regression\" (\"classification\" (default)). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/naiveBayes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Naive Bayes â€” naiveBayes","text":"function training user-defined Naive Bayes model. Hyperparameters tuning: smoothness, Laplace","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"AUC-ROC Curve â€” %>%","title":"AUC-ROC Curve â€” %>%","text":"AUC-ROC Curve Confusion matrix Regression plot Evaluation metrics Classification","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"AUC-ROC Curve â€” %>%","text":"","code":"rocCurve(modelsList, targetVar)  confusionMatrix(modelName, modelsList, targetVar)  regressionPlot(modelName, modelsList, targetVar)  evalMetricsC(modelsList, targetVar)"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"AUC-ROC Curve â€” %>%","text":"modelsList ML ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ targetVar íƒ€ê²Ÿ ë³€ìˆ˜ modelName ëª¨ë¸ëª…","code":""},{"path":"/reference/pipe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"AUC-ROC Curve â€” %>%","text":"ML ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° AUC-ROC Curveë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ML ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ë‚´ íŠ¹ì • ëª¨ë¸ì— ëŒ€í•´ Confusion matrixë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ML ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ ë‚´ íŠ¹ì • ëª¨ë¸ì— ëŒ€í•´ Regression plotë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ML ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° Classification ëª¨ë¸ë“¤ì— ëŒ€í•œ Evaluation metricsë¥¼ ìƒì„±í•©ë‹ˆë‹¤.","code":""},{"path":"/reference/plotRmseComparison.html","id":null,"dir":"Reference","previous_headings":"","what":"rmsePlot â€” plotRmseComparison","title":"rmsePlot â€” plotRmseComparison","text":"rmsePlot","code":""},{"path":"/reference/plotRmseComparison.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"rmsePlot â€” plotRmseComparison","text":"","code":"plotRmseComparison(tunedResultsList, v = v, iter = iter)"},{"path":"/reference/plotRmseComparison.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"rmsePlot â€” plotRmseComparison","text":"rmsePlot","code":""},{"path":"/reference/prepForCV.html","id":null,"dir":"Reference","previous_headings":"","what":"Preprocessing for cross validation â€” prepForCV","title":"Preprocessing for cross validation â€” prepForCV","text":"Preprocessing cross validation","code":""},{"path":"/reference/prepForCV.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preprocessing for cross validation â€” prepForCV","text":"","code":"prepForCV(   data = NULL,   formula = NULL,   imputation = FALSE,   normalization = FALSE,   nominalImputationType = \"mode\",   numericImputationType = \"mean\",   normalizationType = \"range\",   seed = \"4814\" )"},{"path":"/reference/prepForCV.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preprocessing for cross validation â€” prepForCV","text":"data Training dataset apply local preprocessing recipe. formula formula modeling imputation \"imputation = TRUE\", model trained using cross-validation imputation. normalization \"normalization = TRUE\", model trained using cross-validation normalization nominalImputationType Imputation method nominal variable (Option: mode(default), bag, knn) numericImputationType Imputation method numeric variable (Option: mean(default), bag, knn, linear, lower, median, roll) normalizationType Normalization method (Option: range(default), center, normalization, scale) seed seed","code":""},{"path":"/reference/prepForCV.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Preprocessing for cross validation â€” prepForCV","text":"Define local preprocessing method applied training data fold training data divided several folds.","code":""},{"path":"/reference/randomForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Forest â€” randomForest","title":"Random Forest â€” randomForest","text":"Random Forest","code":""},{"path":"/reference/randomForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Forest â€” randomForest","text":"","code":"randomForest(   algo = \"Random Forest\",   engine = \"ranger\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/randomForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Forest â€” randomForest","text":"algo name algorithm can customized user (default: \"Random Forest\"). engine name software used fit model (\"rpart\" (default), \"randomForest\", \"partykit\"). mode model type. \"classification\" \"regression\" (\"classification\" (default), \"regression\"). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/randomForest.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Forest â€” randomForest","text":"function training user-defined Random Forest model. Hyperparameters tuning: trees, min_n, mtry","code":""},{"path":"/reference/trainTestSplit.html","id":null,"dir":"Reference","previous_headings":"","what":"Train-Test Split â€” trainTestSplit","title":"Train-Test Split â€” trainTestSplit","text":"Train-Test Split","code":""},{"path":"/reference/trainTestSplit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train-Test Split â€” trainTestSplit","text":"","code":"trainTestSplit(data = NULL, target = NULL, prop, seed = \"4814\")"},{"path":"/reference/trainTestSplit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train-Test Split â€” trainTestSplit","text":"data Full data set global preprocess completed. target target variable. prop Proportion total data used training data. seed Seed reproducible results.","code":""},{"path":"/reference/trainTestSplit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Train-Test Split â€” trainTestSplit","text":"Separate entire data training set test set.","code":""},{"path":"/reference/xgBoost.html","id":null,"dir":"Reference","previous_headings":"","what":"XGBoost â€” xgBoost","title":"XGBoost â€” xgBoost","text":"function training user-defined XGBoost model. Hyperparameters tuning: tree_depth, trees,learn_rate, mtry, min_n, loss_reduction, sample_size","code":""},{"path":"/reference/xgBoost.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"XGBoost â€” xgBoost","text":"","code":"xgBoost(   algo = \"XGBoost\",   engine = \"xgboost\",   mode = \"classification\",   trainingData = NULL,   splitedData = NULL,   formula = NULL,   rec = NULL,   v = 5,   gridNum = 5,   iter = 10,   metric = NULL,   seed = 1234 )"},{"path":"/reference/xgBoost.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"XGBoost â€” xgBoost","text":"algo name algorithm can customized user (default: \"XGBoost\"). engine name software used fit model (\"xgboost\" (default)). mode model type. \"classification\" \"regression\" (\"classification\" (default), \"regression\"). trainingData training data. splitedData data frame including metadata split. formula formula modeling rec Recipe object containing preprocessing information cross-validation. v Applying v-fold cross validation modeling process (default: 5). gridNum Initial number iterations run starting optimization algorithm. iter maximum number search iterations. metric Metric evaluate performance (classification: \"roc_auc\" (default), \"accuracy\" / regression: \"rmse\" (default), \"rsq\"). seed Seed reproducible results.","code":""},{"path":"/reference/xgBoost.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"XGBoost â€” xgBoost","text":"XGBoost","code":""}]
